---
phase: 07-polish-fixes
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/scrape/parser.ts
autonomous: false
requirements: []

must_haves:
  truths:
    - "Parser extracts paragraphs from both section.talk and section.talk-secondary"
    - "Audience paragraphs have correct speaker labels (e.g., 'Audience')"
    - "Paragraphs from all sections maintain correct document order"
    - "Global Perspectives and Psychedelic Poetics has audience paragraphs after re-scrape"
    - "Spot-check identifies how many other transcripts are affected"
  artifacts:
    - path: "scripts/scrape/parser.ts"
      provides: "Updated parser processing both section.talk and section.talk-secondary"
      contains: "section.talk-secondary"
  key_links:
    - from: "scripts/scrape/parser.ts"
      to: "organism.earth HTML"
      via: "cheerio selector for both talk section types"
      pattern: "section\\.talk.*section\\.talk-secondary"
---

<objective>
Update the corpus scraper parser to extract audience/secondary speaker paragraphs from `section.talk-secondary` elements, then re-scrape the known affected transcript and spot-check others to assess broader impact.

Purpose: Recover missing audience Q&A content from transcripts
Output: Updated parser.ts, re-scraped corpus data for affected transcript(s)
</objective>

<execution_context>
@/Users/bharadwajkulkarni/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bharadwajkulkarni/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-polish-fixes/07-RESEARCH.md
@scripts/scrape/parser.ts
@scripts/scrape/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update parser to process talk-secondary sections</name>
  <files>scripts/scrape/parser.ts</files>
  <action>
Update `parseTranscriptPage` in `scripts/scrape/parser.ts` to process both `section.talk` and `section.talk-secondary` elements in document order.

**Current code (line ~129-166):**
```typescript
const talkSection = $('section.talk');
talkSection.children('p').each((index, pEl) => { ... });
```

**Replace with:**
```typescript
// Process ALL talk sections in document order (both primary and secondary speakers)
const allTalkSections = $('section.talk, section.talk-secondary');

allTalkSections.each((_, sectionEl) => {
  const $section = $(sectionEl);

  // Extract speaker from talk-name if present (for talk-secondary sections)
  // Structure: <div class="talk-meta"><p class="talk-name">Audience</p>...</div>
  let sectionSpeaker: string | null = null;
  const talkName = $section.find('.talk-meta .talk-name').text().trim();
  if (talkName) {
    sectionSpeaker = talkName;
  }

  // Process paragraphs in this section
  $section.children('p').each((_, pEl) => {
    const $p = $(pEl);

    // Skip timestamp paragraphs and talk-name paragraphs
    if ($p.hasClass('talk-timestamp') || $p.hasClass('talk-name')) return;

    // Extract paragraph text
    const text = $p.text().trim();
    if (!text) return;

    // Find preceding timestamp
    let timestamp: string | null = null;
    const $prev = $p.prev();
    if ($prev.is('div.talk-meta')) {
      const timestampText = $prev.find('p.talk-timestamp').text().trim();
      timestamp = timestampText || null;
    }

    // Use section speaker if available, otherwise default to authorName
    const speaker = sectionSpeaker || authorName;

    // Compute content hash
    const contentHash = hashParagraph(text);

    paragraphs.push({
      position: paragraphs.length,
      speaker,
      timestamp,
      text,
      contentHash,
    });
  });
});
```

Key changes:
- `$('section.talk, section.talk-secondary')` selects both section types in document order
- Extract speaker from `.talk-meta .talk-name` within each section
- Speaker falls back to `authorName` (Terence McKenna) when no talk-name is present
- Skip `<p class="talk-name">` elements (they're metadata, not content)
- All existing logic (timestamp extraction, hash, position) preserved
  </action>
  <verify>
    <automated>cd "/Users/bharadwajkulkarni/Documents /Bawa's Lab/mckenna-wiki" && npx tsc --noEmit --project tsconfig.json 2>&1 | grep -c "error" || echo "0 errors"</automated>
    <manual>Review the updated parser code for correctness</manual>
  </verify>
  <done>Parser processes both section.talk and section.talk-secondary, extracting speaker labels and paragraphs in document order</done>
</task>

<task type="auto">
  <name>Task 2: Re-scrape affected transcript and spot-check corpus</name>
  <files>scripts/scrape/parser.ts</files>
  <action>
Run the updated parser against the known affected transcript and a sample of others:

1. **Re-scrape "Global Perspectives and Psychedelic Poetics":**
   ```bash
   cd "/Users/bharadwajkulkarni/Documents /Bawa's Lab/mckenna-wiki"
   npx tsx scripts/scrape/scraper.ts --url "https://www.organism.earth/library/document/global-perspectives-and-psychedelic-poetics" --output corpus/
   ```
   Verify the output JSON has more paragraphs than before (was 57, should be ~67+ with audience content) and that audience paragraphs have speaker="Audience".

2. **Spot-check 5-10 other transcripts** that are likely Q&A format:
   Run the scraper on a sample and compare paragraph counts with what's in the database. Look for transcripts where the new parser produces more paragraphs than the old one stored.

   Use `npx tsx scripts/scrape/scraper.ts --url [URL] --output corpus/` for each, then compare paragraph counts.

3. **Document findings:** Note how many transcripts are affected and the scope of missing content. This informs whether to do a full corpus re-scrape or targeted re-seeds.

**Important:** Do NOT re-seed the database yet — just update the corpus JSON files. Re-seeding will be done manually by the user after verifying the data looks correct (annotations on existing transcripts would be cascade-deleted if paragraphs are re-imported).
  </action>
  <verify>
    <automated>cd "/Users/bharadwajkulkarni/Documents /Bawa's Lab/mckenna-wiki" && cat corpus/global-perspectives-and-psychedelic-poetics.json 2>/dev/null | python3 -c "import sys,json; d=json.load(sys.stdin); print(f'paragraphs: {len(d[\"paragraphs\"])}'); speakers=set(p['speaker'] for p in d['paragraphs']); print(f'speakers: {speakers}')" 2>&1 || echo "File not found - check corpus directory"</automated>
    <manual>Verify audience paragraphs are present and speaker labels are correct</manual>
  </verify>
  <done>Global Perspectives transcript re-scraped with audience content; spot-check completed documenting scope of affected transcripts</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify audience transcript recovery</name>
  <files>scripts/scrape/parser.ts</files>
  <action>Human verification checkpoint — verify parser output and decide on re-seeding scope.</action>
  <verify>
    1. Check corpus/global-perspectives-and-psychedelic-poetics.json — should have more paragraphs than the 57 currently in database
    2. Look for paragraphs with speaker="Audience" in the JSON
    3. Review the spot-check findings to decide: re-scrape all affected transcripts now, or defer to later?
    4. Decision needed: Should we re-seed the database now? (This will delete existing annotations on affected transcripts due to CASCADE)
  </verify>
  <done>User approves parser output and provides re-seeding decision</done>
</task>

</tasks>

<verification>
- [ ] `parseTranscriptPage` processes both `section.talk` and `section.talk-secondary`
- [ ] Audience paragraphs have correct speaker labels (not defaulting to "Terence McKenna")
- [ ] Paragraph positions are sequential across all sections
- [ ] Global Perspectives transcript JSON has audience paragraphs
- [ ] Spot-check results documented
</verification>

<success_criteria>
- Parser handles both talk section types in correct document order
- Known affected transcript re-scraped with audience content recovered
- Scope of broader impact assessed via spot-check
- User informed about re-seeding implications before any database changes
</success_criteria>

<output>
After completion, create `.planning/phases/07-polish-fixes/07-02-SUMMARY.md`
</output>
